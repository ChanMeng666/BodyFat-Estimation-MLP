{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# (iv) Reduced Input Model Development\n",
    "\n",
    "## Model Development and Comparison\n",
    "\n",
    "| Trial No | Nodes in Hidden Layer | Features | MSE |   |   |   | R² |   |   |   |\n",
    "|----------|----------------------|----------|-----|---|---|---|-------|---|---|---|\n",
    "|          |                      |          | Trn | Val | Test | All | Trn | Val | Test | All |\n",
    "| A        | 5                    | Selected | 1.0794 | 0.1992 | 0.2340 | 0.7302 | 0.9861 | 0.9971 | 0.9950 | 0.9895 |\n",
    "| B        | 10                   | Selected | 0.9979 | 0.2352 | 1.1106 | 0.8664 | 0.9871 | 0.9966 | 0.9761 | 0.9876 |\n",
    "| C        | 20                   | Selected | 0.6627 | 0.1270 | 0.3249 | 0.4859 | 0.9915 | 0.9981 | 0.9930 | 0.9930 |\n",
    "\n",
    "## Best Network Analysis\n",
    "\n",
    "### Comparison with Full-Input Models\n",
    "\n",
    "1. **Best Reduced Input Model:**\n",
    "   - 5 neurons in hidden layer\n",
    "   - Test R² = 0.9950\n",
    "   - Test MSE = 0.2340\n",
    "\n",
    "2. **Best Full-Input Model:**\n",
    "   - 20 neurons in hidden layer\n",
    "   - Test R² = 0.9922\n",
    "   - Test MSE = 0.3647\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "1. **Model Simplification:**\n",
    "   - The reduced input model achieves superior performance with fewer neurons (5 vs 20)\n",
    "   - Test error is lower (MSE 0.2340 vs 0.3647)\n",
    "   - Prediction accuracy is higher (R² 0.9950 vs 0.9922)\n",
    "\n",
    "2. **Efficiency Gains:**\n",
    "   - Reduced measurement requirements (9 inputs vs 14)\n",
    "   - Simpler network architecture (5 neurons vs 20)\n",
    "   - Lower computational complexity\n",
    "\n",
    "3. **Performance Consistency:**\n",
    "   - Both models show excellent generalization\n",
    "   - Reduced input model shows more consistent performance across training, validation, and test sets\n",
    "\n",
    "## Possibility of Effective Smaller Model\n",
    "\n",
    "The results strongly support the viability of a smaller, more efficient model:\n",
    "\n",
    "1. **Practical Benefits:**\n",
    "   - Reduces data collection costs by requiring fewer measurements\n",
    "   - Simplifies the measurement process\n",
    "   - Maintains high accuracy despite reduced inputs\n",
    "\n",
    "2. **Model Advantages:**\n",
    "   - More parsimonious architecture\n",
    "   - Potentially faster training and inference\n",
    "   - Reduced risk of overfitting\n",
    "\n",
    "3. **Clinical Implications:**\n",
    "   - More efficient body fat assessment process\n",
    "   - Potential for wider adoption due to simplified requirements\n",
    "   - Maintains high accuracy for reliable health assessment"
   ],
   "id": "ae9de86ff86def01"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-06T01:20:32.082797Z",
     "start_time": "2024-10-06T01:17:34.868046Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Based on best results from part (ii)\n",
    "def create_and_train_model(X_train, X_val, X_test, y_train, y_val, y_test, \n",
    "                          hidden_neurons, learning_rate=0.1, batch_size=32, seed=123):\n",
    "    # Set random seed for reproducibility\n",
    "    tf.random.set_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create model\n",
    "    model = Sequential()\n",
    "    model.add(Input(shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(hidden_neurons, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mse')\n",
    "    \n",
    "    # Early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=100,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        epochs=20000,\n",
    "        batch_size=batch_size,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    X_all = np.vstack([X_train, X_val, X_test])\n",
    "    y_all = np.concatenate([y_train, y_val, y_test])\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred_train = model.predict(X_train, verbose=0)\n",
    "    y_pred_val = model.predict(X_val, verbose=0)\n",
    "    y_pred_test = model.predict(X_test, verbose=0)\n",
    "    y_pred_all = model.predict(X_all, verbose=0)\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse_train = np.mean((y_train - y_pred_train.flatten()) ** 2)\n",
    "    mse_val = np.mean((y_val - y_pred_val.flatten()) ** 2)\n",
    "    mse_test = np.mean((y_test - y_pred_test.flatten()) ** 2)\n",
    "    mse_all = np.mean((y_all - y_pred_all.flatten()) ** 2)\n",
    "    \n",
    "    # Calculate R²\n",
    "    r2_train = r2_score(y_train, y_pred_train)\n",
    "    r2_val = r2_score(y_val, y_pred_val)\n",
    "    r2_test = r2_score(y_test, y_pred_test)\n",
    "    r2_all = r2_score(y_all, y_pred_all)\n",
    "    \n",
    "    return {\n",
    "        'mse': {'train': mse_train, 'val': mse_val, 'test': mse_test, 'all': mse_all},\n",
    "        'r2': {'train': r2_train, 'val': r2_val, 'test': r2_test, 'all': r2_all}\n",
    "    }\n",
    "\n",
    "def prepare_data(selected_features=None):\n",
    "    # Load the data\n",
    "    df = pd.read_csv('Body_Fat.csv')\n",
    "    \n",
    "    if selected_features is None:\n",
    "        X = df.drop('BodyFat', axis=1)\n",
    "    else:\n",
    "        X = df[selected_features]\n",
    "    \n",
    "    y = df['BodyFat']\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = MinMaxScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split the data\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_val, y_train_val, test_size=0.25, random_state=42\n",
    "    )\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def run_experiments():\n",
    "    # Strong correlations identified in part (iii)\n",
    "    selected_features = ['Density', 'Abdomen', 'Chest', 'Hip', 'Weight', \n",
    "                         'Thigh', 'Knee', 'Biceps', 'Neck']\n",
    "    \n",
    "    print(\"Model 1: Using all features\")\n",
    "    X_train_all, X_val_all, X_test_all, y_train, y_val, y_test = prepare_data()\n",
    "    \n",
    "    print(\"Model 2: Using selected features\")\n",
    "    X_train_selected, X_val_selected, X_test_selected, _, _, _ = prepare_data(selected_features)\n",
    "    \n",
    "    results = []\n",
    "    for neurons in [5, 10, 20]:\n",
    "        # Train model with all features\n",
    "        result_all = create_and_train_model(\n",
    "            X_train_all, X_val_all, X_test_all, y_train, y_val, y_test, neurons\n",
    "        )\n",
    "        results.append({\n",
    "            'neurons': neurons,\n",
    "            'features': 'all',\n",
    "            **result_all\n",
    "        })\n",
    "        \n",
    "        # Train model with selected features\n",
    "        result_selected = create_and_train_model(\n",
    "            X_train_selected, X_val_selected, X_test_selected, y_train, y_val, y_test, neurons\n",
    "        )\n",
    "        results.append({\n",
    "            'neurons': neurons,\n",
    "            'features': 'selected',\n",
    "            **result_selected\n",
    "        })\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"\\nNeurons: {neurons}\")\n",
    "        print(\"All Features:\")\n",
    "        print(f\"MSE - Train: {result_all['mse']['train']:.4f}, Val: {result_all['mse']['val']:.4f}, \"\n",
    "              f\"Test: {result_all['mse']['test']:.4f}, All: {result_all['mse']['all']:.4f}\")\n",
    "        print(f\"R² - Train: {result_all['r2']['train']:.4f}, Val: {result_all['r2']['val']:.4f}, \"\n",
    "              f\"Test: {result_all['r2']['test']:.4f}, All: {result_all['r2']['all']:.4f}\")\n",
    "        \n",
    "        print(\"\\nSelected Features:\")\n",
    "        print(f\"MSE - Train: {result_selected['mse']['train']:.4f}, Val: {result_selected['mse']['val']:.4f}, \"\n",
    "              f\"Test: {result_selected['mse']['test']:.4f}, All: {result_selected['mse']['all']:.4f}\")\n",
    "        print(f\"R² - Train: {result_selected['r2']['train']:.4f}, Val: {result_selected['r2']['val']:.4f}, \"\n",
    "              f\"Test: {result_selected['r2']['test']:.4f}, All: {result_selected['r2']['all']:.4f}\")\n",
    "        print(\"-\" * 80)\n",
    "    \n",
    "    # Find best models\n",
    "    best_all = max([r for r in results if r['features'] == 'all'], \n",
    "                   key=lambda x: x['r2']['test'])\n",
    "    best_selected = max([r for r in results if r['features'] == 'selected'], \n",
    "                        key=lambda x: x['r2']['test'])\n",
    "    \n",
    "    print(\"\\nBest Model with All Features:\")\n",
    "    print(f\"Neurons: {best_all['neurons']}\")\n",
    "    print(f\"Test R²: {best_all['r2']['test']:.4f}\")\n",
    "    print(f\"Test MSE: {best_all['mse']['test']:.4f}\")\n",
    "    \n",
    "    print(\"\\nBest Model with Selected Features:\")\n",
    "    print(f\"Neurons: {best_selected['neurons']}\")\n",
    "    print(f\"Test R²: {best_selected['r2']['test']:.4f}\")\n",
    "    print(f\"Test MSE: {best_selected['mse']['test']:.4f}\")\n",
    "    \n",
    "    return results, best_all, best_selected\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results, best_all, best_selected = run_experiments()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: Using all features\n",
      "Model 2: Using selected features\n",
      "\n",
      "Neurons: 5\n",
      "All Features:\n",
      "MSE - Train: 1.7193, Val: 0.5089, Test: 0.5141, All: 1.2304\n",
      "R² - Train: 0.9778, Val: 0.9926, Test: 0.9889, All: 0.9824\n",
      "\n",
      "Selected Features:\n",
      "MSE - Train: 1.0794, Val: 0.1992, Test: 0.2340, All: 0.7302\n",
      "R² - Train: 0.9861, Val: 0.9971, Test: 0.9950, All: 0.9895\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Neurons: 10\n",
      "All Features:\n",
      "MSE - Train: 0.7903, Val: 0.3538, Test: 0.5872, All: 0.6609\n",
      "R² - Train: 0.9898, Val: 0.9948, Test: 0.9874, All: 0.9905\n",
      "\n",
      "Selected Features:\n",
      "MSE - Train: 0.9979, Val: 0.2352, Test: 1.1106, All: 0.8664\n",
      "R² - Train: 0.9871, Val: 0.9966, Test: 0.9761, All: 0.9876\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Neurons: 20\n",
      "All Features:\n",
      "MSE - Train: 0.8498, Val: 0.3190, Test: 0.3647, All: 0.6442\n",
      "R² - Train: 0.9890, Val: 0.9953, Test: 0.9922, All: 0.9908\n",
      "\n",
      "Selected Features:\n",
      "MSE - Train: 0.6627, Val: 0.1270, Test: 0.3249, All: 0.4859\n",
      "R² - Train: 0.9915, Val: 0.9981, Test: 0.9930, All: 0.9930\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Best Model with All Features:\n",
      "Neurons: 20\n",
      "Test R²: 0.9922\n",
      "Test MSE: 0.3647\n",
      "\n",
      "Best Model with Selected Features:\n",
      "Neurons: 5\n",
      "Test R²: 0.9950\n",
      "Test MSE: 0.2340\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
